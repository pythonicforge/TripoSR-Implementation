{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA-uPN-9TLUb"
   },
   "source": [
    "# TripoSR Reimplementation â€” 3D Mesh from a Single Image\n",
    "\n",
    "Welcome to this notebook where I will walk you through a **reimplementation of TripoSR**, a fast and powerful 3D object reconstruction model that takes a **single 2D image** and generates a **textured 3D mesh**.\n",
    "\n",
    "This implementation is based on the original work by [Tripo AI](https://github.com/VAST-AI-Research/TripoSR) and adapted using the excellent tutorial by [PyImageSearch](https://pyimagesearch.com/2024/11/25/create-a-3d-object-from-your-images-with-triposr-in-python/). The goal here is to understand how the model works, and recreate the workflow in a clean, reproducible, and Colab-friendly format ðŸš€\n",
    "\n",
    "<br/>\n",
    "\n",
    "### What I'll Do Here\n",
    "\n",
    "- Clone the TripoSR repo and set it up in Colab\n",
    "- Install all required dependencies (with ðŸ’€ Mac fixes if needed)\n",
    "- Upload your own image or use a sample one\n",
    "- Generate a 3D mesh using the pre-trained TripoSR model\n",
    "- Visualize the result interactively\n",
    "\n",
    "> **Note**: This is a *reimplementation and walkthrough*, not an official version â€” credits go to the original authors and sources linked below.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### References\n",
    "\n",
    "- [TripoSR Paper (arXiv)](https://arxiv.org/pdf/2403.02151)\n",
    "- [Official GitHub Repo](https://github.com/VAST-AI-Research/TripoSR)\n",
    "- [PyImageSearch Blog Walkthrough](https://pyimagesearch.com/2024/11/25/create-a-3d-object-from-your-images-with-triposr-in-python/)\n",
    "\n",
    "<br/>\n",
    "\n",
    "Letâ€™s dive in and build some 3D magic from 2D pixels âœ¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGE1Evu7Upi-"
   },
   "source": [
    "### Clone the GitHub Repository\n",
    "\n",
    "I'll use [PyImageSearch's Repo](https://github.com/pyimagesearch/TripoSR) to clone the source code for TripoSR. Since we're working inside Google Colab, so we use `%cd` to change the working directory and `sys.path.append` to import local modules like `tsr.infer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxvQyevRMXf0",
    "outputId": "14d0ed97-0c77-4ca6-db67-ae91eab4b757"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pyimagesearch/TripoSR.git\n",
    "import sys\n",
    "sys.path.append('/content/TripoSR/tsr')\n",
    "%cd TripoSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUUyYHGQVY95"
   },
   "source": [
    "### Install Required Dependencies\n",
    "\n",
    "To run TripoSR, we'll need to install a few Python packages including PyTorch, ONNX Runtime, and some image processing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXtSIbFhMbDm",
    "outputId": "77305c96-5227-4784-8949-7aa2756ee669"
   },
   "outputs": [],
   "source": [
    "# Install all dependencies listed in the repo's requirements.txt\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Install ONNX Runtime for running the model inference\n",
    "!pip install onnxruntime\n",
    "\n",
    "# Pillow upgrade is needed for proper image handling (especially for mesh\n",
    "# textures)\n",
    "!pip install --upgrade Pillow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdRprctxWTba"
   },
   "source": [
    "### Import Libraries & Utilities\n",
    "\n",
    "Weâ€™ll now import all the core libraries needed for this reimplementation. This includes:\n",
    "- `torch` for GPU support and tensor ops\n",
    "- `Pillow` & `rembg` for image processing and background removal\n",
    "- `TSR` for the main model\n",
    "- `pymeshlab` for mesh manipulation\n",
    "- `IPython.display` to show the output as a video right in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCcFxSmVMhG-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import Video\n",
    "\n",
    "# TripoSR system and utility functions\n",
    "from tsr.system import TSR\n",
    "from tsr.utils import remove_background, resize_foreground, save_video\n",
    "\n",
    "# Mesh handling and background removal\n",
    "import pymeshlab as pymesh\n",
    "import rembg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmsYRWCPWgac"
   },
   "source": [
    "### Select Device (GPU or CPU)\n",
    "\n",
    "We'll check if a CUDA-enabled GPU is available and set our device accordingly. If you're using Google Colab with GPU runtime enabled, it should default to `\"cuda\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "it8ItMZTPs7y"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btGAZFb4Vs8D"
   },
   "source": [
    "### Create a Timer Utility Class\n",
    "\n",
    "We'll define a simple `Timer` class to measure how long different parts of the pipeline take â€” especially useful when comparing performance across devices (CPU vs GPU).\n",
    "\n",
    "This class:\n",
    "- Automatically syncs with CUDA (if available) for accurate timing\n",
    "- Stores timing data in a dictionary\n",
    "- Prints the duration of each operation in **milliseconds (ms)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHP1HRceP9ne"
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "  def __init__(self):\n",
    "    self.items = {}\n",
    "    self.time_scale = 1000.0\n",
    "    self.time_unit = \"ms\"\n",
    "\n",
    "  def start(self, name: str) -> None:\n",
    "    if torch.cuda.is_available():\n",
    "      torch.cuda.synchronize()\n",
    "    self.items[name] = time.time()\n",
    "\n",
    "  def end(self, name: str) -> float:\n",
    "    if name not in self.items:\n",
    "      return\n",
    "    if torch.cuda.is_available():\n",
    "      torch.cuda.synchronize\n",
    "    start_time = self.items.pop(name)\n",
    "    delta = time.time() - start_time\n",
    "    t = delta * self.time_scale\n",
    "    print(f\"{name} finished in {t:.2f}{self.time_unit}.\")\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lshua-ezXG4_"
   },
   "source": [
    "### Upload Your 2D Image\n",
    "\n",
    "Now it's your turn! Upload any 2D image (preferably of a single object) that you'd like to convert into a 3D mesh.\n",
    "\n",
    "This code:\n",
    "- Opens a file upload dialog in Colab\n",
    "- Loads the first uploaded image using `Pillow`\n",
    "- Resizes it to **512Ã—512** (TripoSR expects square inputs)\n",
    "- Saves it to the `examples/` folder as `product.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "VVU-NHnYQ18k",
    "outputId": "873bb516-6649-403f-9261-c5d99035e5f5"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded image\n",
    "original_image = Image.open(list(uploaded.keys())[0])\n",
    "\n",
    "# Resize and save in the format expected by TripoSR\n",
    "original_image.resize((512, 512)).save(\"examples/product.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPBToBXOXHkZ"
   },
   "source": [
    "### Configure Inference Parameters\n",
    "\n",
    "Here we define all the key settings for running the TripoSR model:\n",
    "\n",
    "- `image_paths`: Path to the input image  \n",
    "- `pretrained_model_name_or_path`: Hugging Face model name or path  \n",
    "- `device`: CUDA GPU device for inference (or CPU fallback)  \n",
    "- `chunk_size`: Controls how much data gets processed at once (default = 8192)  \n",
    "- `no_remove_bg`: If `True`, skips background removal (set `False` to enable)  \n",
    "- `foreground_ratio`: Resize factor for foreground cropping  \n",
    "- `output_dir`: Folder to save the generated mesh + render  \n",
    "- `model_save_format`: File format for the saved mesh (e.g., `\"obj\"`)  \n",
    "- `render`: Whether to generate a render video or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrjteFePQ9MD"
   },
   "outputs": [],
   "source": [
    "image_paths = \"/content/TripoSR/examples/product.png\"\n",
    "device = \"cuda:0\"\n",
    "pretrained_model_name_or_path = \"stabilityai/TripoSR\"\n",
    "chunk_size = 8192\n",
    "no_remove_bg = True\n",
    "foreground_ratio = 0.85\n",
    "output_dir = \"output/\"\n",
    "model_save_format = \"obj\"\n",
    "render = True\n",
    "\n",
    "# Make sure the output directory exists\n",
    "output_dir = output_dir.strip()\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL2zjOzTXeL7"
   },
   "source": [
    "### Load the Pretrained TripoSR Model\n",
    "\n",
    "Weâ€™ll now load the **pretrained TripoSR model** from Hugging Face using the built-in `TSR.from_pretrained()` method.\n",
    "\n",
    "This step:\n",
    "- Loads model weights + config from `\"stabilityai/TripoSR\"`\n",
    "- Sets the rendering chunk size\n",
    "- Moves the model to the specified device (`cuda` or `cpu`)\n",
    "- Times the whole process using our custom `Timer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "6c7e6d0689404a449bf1fcc1b0a2a334",
      "6a7950d452be487d8c7b6ef91dd56772",
      "9d7dc752a7434b30a1fa0ff002059dbb",
      "a0709bc09d4f4a5b9a7caaa1100cb9d7",
      "f8487a17f3264fab84057fda8534056d",
      "61cb09d224234ba799d5b23cfc3f64b1",
      "d9d28a7e036941579f771bb650bf7af7",
      "280e0f5e63d848b4aa347341f4a66fce",
      "81392de78507430d8f8c7d65b585de09",
      "42b6347aa75749d389961f9f79861703",
      "38d56e6d4ccf443ca1922d8de59fc9ca"
     ]
    },
    "id": "F9n4qQapSUD6",
    "outputId": "03ddbb0b-bae3-4aa3-bd47-c23e4e525217"
   },
   "outputs": [],
   "source": [
    "timer.start(\"Initializing model\")\n",
    "model = TSR.from_pretrained(\n",
    "    pretrained_model_name_or_path, # HF model hub path\n",
    "    config_name=\"config.yaml\", # Model config\n",
    "    weight_name=\"model.ckpt\", # Pretrained weights\n",
    ")\n",
    "\n",
    "# Set chunk size for renderer\n",
    "model.renderer.set_chunk_size(chunk_size)\n",
    "\n",
    "# Move model to GPU or CPU\n",
    "model.to(device)\n",
    "\n",
    "timer.end(\"Initializing model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjePWk3FX3Pw"
   },
   "source": [
    "### Preprocess the Input Image\n",
    "\n",
    "Now letâ€™s get our uploaded image ready for TripoSR. This step involves:\n",
    "\n",
    "- **Removing the background** (optional with `rembg`)\n",
    "- **Cropping + resizing the foreground** to focus on the object\n",
    "- **Handling transparency (RGBA)** by compositing it onto a neutral background\n",
    "- Saving the final processed image to disk\n",
    "\n",
    "We're also timing this step to see how long preprocessing takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GSfYutPSxY0",
    "outputId": "e57d20ef-c3de-4192-c8be-2c33c3b078eb"
   },
   "outputs": [],
   "source": [
    "timer.start(\"Processing images\")\n",
    "\n",
    "images = []\n",
    "rembg_session = rembg.new_session()\n",
    "\n",
    "# Remove background using Rembg (unless disabled)\n",
    "image_with_bg_removed = remove_background(original_image, rembg_session)\n",
    "\n",
    "# Resize + crop based on foreground\n",
    "image = resize_foreground(image_with_bg_removed, foreground_ratio)\n",
    "\n",
    "# Handle RGBA transparency blending\n",
    "if image.mode == \"RGBA\":\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[:, :, :3] * image[:, :, 3:4] + (1 - image[:, :, 3:4]) * 0.5\n",
    "    image = Image.fromarray((image * 255.0).astype(np.uint8))\n",
    "\n",
    "# Save processed image\n",
    "image_dir = os.path.join(output_dir, str(0))\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "image.save(os.path.join(image_dir, \"input.png\"))\n",
    "\n",
    "# Append to list for inference\n",
    "images.append(image)\n",
    "\n",
    "timer.end(\"Processing images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdeOdOrrYUGX"
   },
   "source": [
    "### Run TripoSR on the Image (Inference, Render & Export)\n",
    "\n",
    "Now comes the fun part! Weâ€™ll:\n",
    "- Run the model on the processed image\n",
    "- Generate a **360Â° render** of the object (30 views)\n",
    "- Save the rendered frames and a `.mp4` turntable video\n",
    "- Extract and export the **3D mesh** in your chosen format (default: `.obj`)\n",
    "\n",
    "All steps are timed with our `Timer` class for performance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HIuWKAcVH_F",
    "outputId": "01079516-b5de-4f47-9fc0-4c5ae5995a07"
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(images):\n",
    "    print(f\"Running image {i + 1}/{len(images)} ...\")\n",
    "\n",
    "    # Inference\n",
    "    timer.start(\"Running model\")\n",
    "    with torch.no_grad():\n",
    "        scene_codes = model([image], device=device)\n",
    "    timer.end(\"Running model\")\n",
    "\n",
    "    # Render turntable video\n",
    "    if render:\n",
    "        timer.start(\"Rendering\")\n",
    "        render_images = model.render(scene_codes, n_views=30, return_type=\"pil\")\n",
    "        for ri, render_image in enumerate(render_images[0]):\n",
    "            render_image.save(os.path.join(output_dir, str(i), f\"render_{ri:03d}.png\"))\n",
    "        save_video(\n",
    "            render_images[0], os.path.join(output_dir, str(i), \"render.mp4\"), fps=30\n",
    "        )\n",
    "        timer.end(\"Rendering\")\n",
    "\n",
    "    # Export mesh\n",
    "    timer.start(\"Exporting mesh\")\n",
    "    meshes = model.extract_mesh(scene_codes, has_vertex_color=False)\n",
    "    mesh_file = os.path.join(output_dir, str(i), f\"mesh.{model_save_format}\")\n",
    "    meshes[0].export(mesh_file)\n",
    "    timer.end(\"Exporting mesh\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc75ol9TYt3n"
   },
   "source": [
    "### Preview the Rendered 3D Model\n",
    "\n",
    "Letâ€™s check out what we just created! Here's a **360Â° turntable render** of your object, stitched from 30 different viewpoints. Super useful to visually validate the result before working with the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "0QLecKTjKNLo",
    "outputId": "40e33398-d5ff-4f9c-b675-8b7fbfb2645f"
   },
   "outputs": [],
   "source": [
    "Video('output/0/render.mp4', embed=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
